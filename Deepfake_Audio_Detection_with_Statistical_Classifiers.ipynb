{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vX9yu7hn8pny",
        "OoVkjzLi9HaU",
        "b2qTC1NV_P1I",
        "OjVNNAmrj3T5"
      ],
      "name": "Deepfake Audio Detection with Statistical Classifiers",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulkumarrathore/Deepfake-Audio-Detection-with-Statistical-Classifiers/blob/main/Deepfake_Audio_Detection_with_Statistical_Classifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlDE7aoUufVt"
      },
      "outputs": [],
      "source": [
        "#MOUNT TO SAVE AND LOAD df of built datasets\n",
        "#to mount the personal 1612 gmail drive (IMP)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_path = '/content/drive/MyDrive/AiAudio_PR_Project/AiAudio_Dataset'\n",
        "for_2sec_df_path = df_path+'/for_2sec' #will use it to train and select best model\n",
        "for_2sec_rerec_df_path = df_path+'/for_2sec_rerec' #retrain, for our scenario, on the selected best model\n",
        "\n",
        "print(\"Path to dataset files:\", for_2sec_df_path)\n",
        "print(\"Path to dataset files:\", for_2sec_rerec_df_path)"
      ],
      "metadata": {
        "id": "_C0FXQVMm3Y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4_72DtKW70cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting data"
      ],
      "metadata": {
        "id": "GoRsIXSaxb8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"mohammedabdeldayem/the-fake-or-real-dataset\")\n"
      ],
      "metadata": {
        "id": "Waw-x0wixbkk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bb83f8e-7932-4377-d2fb-4f6ef03599d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.0).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mohammedabdeldayem/the-fake-or-real-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|â–Ž         | 608M/16.0G [00:21<08:43, 31.7MB/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "cnn_path = os.path.join(path, \"for-2sec/for-2seconds\")\n",
        "for_2sec_path=os.path.join(path, \"for-2sec/for-2seconds/training\")\n",
        "for_2sec_test_path=os.path.join(path, \"for-2sec/for-2seconds/testing\")\n",
        "for_2sec_valid_path=os.path.join(path, \"for-2sec/for-2seconds/validation\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "print(\"Path to dataset files:\", for_2sec_path)"
      ],
      "metadata": {
        "id": "3_XWi7fLitiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RERECORDED FoR DATA, FOR INFERENCE\n",
        "for_rerec_path_real = os.path.join(path, \"for-rerec/for-rerecorded/validation/real\")\n",
        "for_rerec_path_fake = os.path.join(path, \"for-rerec/for-rerecorded/validation/fake\")\n",
        "\n",
        "print(\"Path to rerec real files:\", for_rerec_path_real)\n",
        "print(\"Path to rerec fake files:\", for_rerec_path_fake)"
      ],
      "metadata": {
        "id": "GamQBUpDnjvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Extraction"
      ],
      "metadata": {
        "id": "Edeixz-5HpQh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Function"
      ],
      "metadata": {
        "id": "ravo9umSHwWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def extract_features(file_path):\n",
        "    y, sr = librosa.load(file_path, sr=16000)\n",
        "\n",
        "\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "\n",
        "    delta_mfccs = librosa.feature.delta(mfccs)\n",
        "\n",
        "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "\n",
        "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "\n",
        "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "\n",
        "    zcr = librosa.feature.zero_crossing_rate(y)\n",
        "\n",
        "    rms = librosa.feature.rms(y=y)\n",
        "\n",
        "\n",
        "    features = []\n",
        "    for feature_set in [mfccs, delta_mfccs, spec_cent, spec_bw, chroma, zcr, rms]:\n",
        "        features.extend(np.mean(feature_set, axis=1))\n",
        "        features.extend(np.std(feature_set, axis=1))\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def build_dataset(base_dir):\n",
        "    data = []\n",
        "    for label_dir in ['real', 'fake']:\n",
        "        folder = os.path.join(base_dir, label_dir)\n",
        "        label = 0 if label_dir == 'real' else 1\n",
        "        for fname in os.listdir(folder):\n",
        "            fpath = os.path.join(folder, fname)\n",
        "            try:\n",
        "                feats = extract_features(fpath)\n",
        "                data.append([fpath] + feats + [label])\n",
        "            except Exception as e:\n",
        "                print(f\"Error with {fpath}: {e}\")\n",
        "    return data\n",
        "\n",
        "\n",
        "feature_names = [f'mfcc{i}' for i in range(13)] + \\\n",
        "                [f'delta_mfcc{i}' for i in range(13)] + \\\n",
        "                ['spec_cent', 'spec_bw'] + \\\n",
        "                [f'chroma{i}' for i in range(12)] + \\\n",
        "                ['zcr', 'rms']\n",
        "\n",
        "feature_names = [f\"{f}_{stat}\" for f in feature_names for stat in ['mean', 'std']]\n",
        "df_cols = ['filename'] + feature_names + ['label']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Oxnb6Wki3WA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##for_2sec Dataset"
      ],
      "metadata": {
        "id": "zG952YegofWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**No need to run Below again, just load pre-save(unprocessed)**"
      ],
      "metadata": {
        "id": "W2uW5GwxpPn1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The training dataset"
      ],
      "metadata": {
        "id": "e1tSZcCk8nod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = build_dataset(for_2sec_path)\n",
        "df = pd.DataFrame(dataset, columns=df_cols)"
      ],
      "metadata": {
        "id": "6U4cQIBV8EMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "bzt21ojO0G4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "yniToxFw0o7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "nI5K9WVO6cc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(for_2sec_df_path+\"/training_df.pkl\")"
      ],
      "metadata": {
        "id": "-_jX0ep-pmSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_pickle(f\"{for_2sec_df_path}/training_df.pkl\")"
      ],
      "metadata": {
        "id": "hp9CasOalj0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The testing set"
      ],
      "metadata": {
        "id": "vX9yu7hn8pny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test = build_dataset(for_2sec_test_path)\n",
        "df_test = pd.DataFrame(dataset_test, columns=df_cols)"
      ],
      "metadata": {
        "id": "r9Rsfb5J6wS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head()"
      ],
      "metadata": {
        "id": "wPL7p93S82QO",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.tail()"
      ],
      "metadata": {
        "id": "50EoxQlI84WK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.shape"
      ],
      "metadata": {
        "id": "qTMNoBPm86n1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.to_pickle(f\"{for_2sec_df_path}/testing_df.pkl\")"
      ],
      "metadata": {
        "id": "oR7agOigo4Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Dataset\n"
      ],
      "metadata": {
        "id": "ABlNTch9lA8c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**for_2sec**"
      ],
      "metadata": {
        "id": "aXwg93DNldZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_pickle(f\"{for_2sec_df_path}/training_df.pkl\")\n",
        "df_test = pd.read_pickle(f\"{for_2sec_df_path}/testing_df.pkl\")"
      ],
      "metadata": {
        "id": "aBoOKkhvlD2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "id": "YuAeAuexKp6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "OoVkjzLi9HaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df.drop(columns=['filename', 'label'])\n",
        "y_train = df['label']\n",
        "\n",
        "X_test = df_test.drop(columns=['filename', 'label'])\n",
        "y_test = df_test['label']"
      ],
      "metadata": {
        "id": "a7b94T029Cg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling as the ranges of features varies accross all\n",
        "#We scale because statistical classifiers (like logistic regression, SVM, KNN, LDA) are sensitive to the scale (range) of feature values.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)  # Important: use transform, not fit_transform"
      ],
      "metadata": {
        "id": "VsQs9yiy-OCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "Yaa-o6rH-mVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled"
      ],
      "metadata": {
        "id": "vu7i1oz5-Rur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models Selection"
      ],
      "metadata": {
        "id": "b2qTC1NV_P1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "muh4k8XcANjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Comparing 3 Statistical classifiers"
      ],
      "metadata": {
        "id": "JiX2JbbQIX78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "print(\"RF:\", rf.score(X_test_scaled, y_test))\n",
        "\n",
        "\n",
        "svm = SVC(kernel='rbf', C=1, gamma='scale')\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "print(\"SVM:\", svm.score(X_test_scaled, y_test))\n",
        "\n",
        "\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "print(\"LR:\", lr.score(X_test_scaled, y_test))\n"
      ],
      "metadata": {
        "id": "k5E0dB-F_RvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"SVM Report:\")\n",
        "print(classification_report(y_test, svm.predict(X_test_scaled)))\n",
        "\n",
        "print(\"LogReg Report:\")\n",
        "print(classification_report(y_test, lr.predict(X_test_scaled)))\n"
      ],
      "metadata": {
        "id": "R92ab2WS_ytM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM** - because lr is less stable"
      ],
      "metadata": {
        "id": "GHaE_I9wAKYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SVM"
      ],
      "metadata": {
        "id": "UwPjEQFLA7mC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Tuning & COMPARING svm hyperparameters"
      ],
      "metadata": {
        "id": "zRv0F9XCAGtD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ReSeaching The good params - cv=3 gave gamma as scale while 5 giving"
      ],
      "metadata": {
        "id": "Whdn9idQLUIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': ['scale', 'auto', 1, 0.1, 0.01, 0.001],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(SVC(), param_grid=params, cv=5, scoring='f1', verbose=1)\n",
        "grid.fit(X_train_scaled, y_train)\n",
        "print(\"Best Params:\", grid.best_params_)\n",
        "print(\"Best F1 Score:\", grid.best_score_)\n",
        "print(\"Best Mean Test Score:\", grid.cv_results_['mean_test_score'])\n",
        "print(\"Best Mean Train Score:\", grid.cv_results_['mean_train_score'])"
      ],
      "metadata": {
        "id": "EPyoWDbZktjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM**\n",
        "- Best Params: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
        "- Best F1 Score: 0.9896433774231864\n"
      ],
      "metadata": {
        "id": "kZe3rnhdVD28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####The SVM model on 86 feaTURES- gamma 0.01 & scale"
      ],
      "metadata": {
        "id": "ZpTeAfhYVGmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='rbf', C=10, gamma=0.01) #The best svm parameters from tuning and comparing\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "print(\"SVM:\", svm.score(X_test_scaled, y_test))"
      ],
      "metadata": {
        "id": "8KbviiE1VKru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### svm model with feature reducced- chroma removed (86-24)"
      ],
      "metadata": {
        "id": "SFSGcQ_BNetR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing chroma features**"
      ],
      "metadata": {
        "id": "o1D_VUdvN-Ek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#triming the features\n",
        "df_reduced = df.loc[:, ~df.columns.str.startswith('chroma')]\n",
        "df_test_reduced = df_test.loc[:, ~df_test.columns.str.startswith('chroma')]\n",
        "\n",
        "print(df_reduced.columns.tolist())\n",
        "print(df_reduced.shape)\n",
        "\n",
        "print(df_test_reduced.columns.tolist())\n",
        "print(df_test_reduced.shape)"
      ],
      "metadata": {
        "id": "nu7IhiPpNYWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing new reduced dataserrt"
      ],
      "metadata": {
        "id": "y-Jcf8a_N_p4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_reduced_train = df_reduced.drop(columns=['filename', 'label'])\n",
        "\n",
        "X_reduced_test = df_test_reduced.drop(columns=['filename', 'label'])"
      ],
      "metadata": {
        "id": "lAhX-0ZbOCe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_reduced_train.shape"
      ],
      "metadata": {
        "id": "njrp_6EA6V3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler2 = StandardScaler()\n",
        "X_reduced_train_scaled = scaler2.fit_transform(X_reduced_train)\n",
        "X_reduced_test_scaled = scaler2.transform(X_reduced_test)  # Important: use transform, not fit_transform"
      ],
      "metadata": {
        "id": "NTGHHjtjOiTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_reduced_train"
      ],
      "metadata": {
        "id": "bdGjf7WL0tmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_reduced_train_scaled"
      ],
      "metadata": {
        "id": "GPVlBCa60wOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and comparing"
      ],
      "metadata": {
        "id": "7mxNdp7HW3Oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_reduced = SVC(kernel='rbf', C=10, gamma=0.01)\n",
        "svm_reduced.fit(X_reduced_train_scaled, y_train)\n",
        "print(\"SVM:\", svm_reduced.score(X_reduced_test_scaled, y_test))"
      ],
      "metadata": {
        "id": "2q_tBym8W7Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_reduced = LogisticRegression(C=0.1, max_iter=500, penalty='l1',solver='liblinear')\n",
        "lr_reduced.fit(X_reduced_train_scaled, y_train)\n",
        "print(\"LR:\", lr_reduced.score(X_reduced_test_scaled, y_test))"
      ],
      "metadata": {
        "id": "_-8AmaMBnpNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONCLUSION** : NOT TO REDUCE FEATURE SET as it cost ACCURACY ~ Thus not saving the reduceSVM model\n"
      ],
      "metadata": {
        "id": "BJrz3_ooApHq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### svm model with feature reducced- PCA applied ()"
      ],
      "metadata": {
        "id": "h2f3QlTZG5Yk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LR"
      ],
      "metadata": {
        "id": "SJX1Km_zBT8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####TUning and  choosing hyperparameters"
      ],
      "metadata": {
        "id": "O3l3ZEtFBVtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],   # Regularization strength (inverse of lambda)\n",
        "    'penalty': ['l1', 'l2', 'elasticnet'], # Different regularization types\n",
        "    'solver': ['liblinear','saga'],       # solvers that support l1 and elasticnet\n",
        "    'max_iter': [500, 1000]\n",
        "}\n",
        "\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "grid = GridSearchCV(log_reg, param_grid=params, cv=5, scoring='f1', verbose=1, n_jobs=-1)\n",
        "grid.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Display best parameters and best score\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best F1 Score:\", grid.best_score_)\n",
        "\n",
        "# Best model\n",
        "best_lr = grid.best_estimator_\n"
      ],
      "metadata": {
        "id": "HpeVt-nPRKXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LR**\n",
        "- Best Parameters: {'C': 0.1, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear'}\n",
        "- Best F1 Score: 0.9098175641027335"
      ],
      "metadata": {
        "id": "uoZiZhrYU7eE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LORIS** - ensumbled LR & SVM"
      ],
      "metadata": {
        "id": "OjVNNAmrj3T5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "dZSX2tvxj9AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "svm_loris = SVC(kernel='rbf', C=10, gamma=0.01, probability=True)\n",
        "lr_loris  = LogisticRegression(C=0.1, max_iter=500, penalty='l1',solver='liblinear')\n",
        "\n",
        "# For storing results\n",
        "weights = np.arange(0.5, 1.0, 0.1)  #this weight for the lr\n",
        "ai_f1_scores = []\n",
        "human_f1_scores = []\n",
        "macro_f1_scores = []\n",
        "accuracies = []\n",
        "\n",
        "for w in weights:\n",
        "    svm_w = 1 - w\n",
        "    lr_w  = w\n",
        "\n",
        "    ensemble = VotingClassifier(\n",
        "        estimators=[('svm', svm_loris), ('lr', lr_loris)],\n",
        "        voting='soft',\n",
        "        weights=[svm_w, lr_w]\n",
        "    )\n",
        "\n",
        "\n",
        "    ensemble.fit(X_train_scaled, y_train)\n",
        "\n",
        "    y_pred = ensemble.predict(X_test_scaled)\n",
        "\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    human_f1 = report['0']['f1-score']\n",
        "    ai_f1    = report['1']['f1-score']\n",
        "    macro_f1 = report['macro avg']['f1-score']\n",
        "    acc      = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    human_f1_scores.append(human_f1)\n",
        "    ai_f1_scores.append(ai_f1)\n",
        "    macro_f1_scores.append(macro_f1)\n",
        "    accuracies.append(acc)\n",
        "\n",
        "    print(f\"LR weight={w:.1f} | AI F1={ai_f1:.3f} | Human F1={human_f1:.3f} | Macro F1={macro_f1:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "vqH2zc-Sj77z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------\n",
        "# Plot Performance vs LR Weight\n",
        "# -----------------------------\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(weights, ai_f1_scores, marker='o', label='AI Class F1-score')\n",
        "plt.plot(weights, human_f1_scores, marker='o', label='Human Class F1-score')\n",
        "plt.plot(weights, macro_f1_scores, marker='o', label='Macro F1-score')\n",
        "plt.plot(weights, accuracies, marker='o', label='Accuracy')\n",
        "\n",
        "plt.title(\"Performance vs Logistic Regression Weight\")\n",
        "plt.xlabel(\"Weight for Logistic Regression (LR)\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AWDbn2AEkgK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MODEL\n"
      ],
      "metadata": {
        "id": "0OFyuuNSD9Fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "s2xLpWqXnwAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/AiAudio_PR_Project/AiAudio_Model'\n",
        "svm_m_path = model_path+'/svm' #will use it to train and select best model\n",
        "svm_reduced_m_path = model_path+'/svm_reduced'\n",
        "lr_m_path = model_path+'/lr'\n",
        "lr_reduced_m_path = model_path + '/lr_reduced' #retrain, for our scenario, on the selected best model\n",
        "loris1_m_path = model_path + '/loris1'\n",
        "loris2_m_path = model_path + '/loris2'\n",
        "\n",
        "print(\"Path to SVM Model:\", svm_m_path)\n",
        "print(\"Path to SVM Reduced Model:\", svm_reduced_m_path)\n",
        "print(\"Path to LR Model:\", lr_m_path)"
      ],
      "metadata": {
        "id": "itLtunPjEYRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving Model\n"
      ],
      "metadata": {
        "id": "w5Vv36r6D-ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "4iNPgNMydU3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(svm_m_path, \"wb\") as f:\n",
        "    pickle.dump(svm, f)\n",
        "\n",
        "print(f\"Model saved at: {svm_m_path}\")\n"
      ],
      "metadata": {
        "id": "d1ViZ2OOEB7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LR"
      ],
      "metadata": {
        "id": "qt7qNpOldVys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(lr_m_path, \"wb\") as f:\n",
        "    pickle.dump(lr, f)\n",
        "\n",
        "print(f\"Model saved at: {lr_m_path}\")\n"
      ],
      "metadata": {
        "id": "eIdaVkwrdW1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM_REDUCED (NO CHROMA)"
      ],
      "metadata": {
        "id": "j42zrzmSDu9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(svm_reduced_m_path, \"wb\") as f:\n",
        "    pickle.dump(svm_reduced, f)\n",
        "\n",
        "print(f\"Model saved at: {svm_reduced_m_path}\")\n"
      ],
      "metadata": {
        "id": "SRr4Xo98Dxin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LR_Reduced"
      ],
      "metadata": {
        "id": "C2Qt-xXpo9Tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(lr_reduced_m_path, \"wb\") as f:\n",
        "    pickle.dump(lr_reduced, f)\n",
        "\n",
        "print(f\"Model saved at: {lr_reduced_m_path}\")\n"
      ],
      "metadata": {
        "id": "kl73-25ho-1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loris 1 and 2"
      ],
      "metadata": {
        "id": "KSFUlY99oKUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(loris1_m_path, \"wb\") as f:\n",
        "    pickle.dump(loris1, f)\n",
        "\n",
        "print(f\"Model saved at: {loris1_m_path}\")"
      ],
      "metadata": {
        "id": "DuWO2CF3oLbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(loris2_m_path, \"wb\") as f:\n",
        "    pickle.dump(loris2, f)\n",
        "\n",
        "print(f\"Model saved at: {loris2_m_path}\")"
      ],
      "metadata": {
        "id": "jfBueVa0oseG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading Model\n"
      ],
      "metadata": {
        "id": "yDt2PuHMEAah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(svm_m_path, \"rb\") as f:\n",
        "    svm = pickle.load(f)"
      ],
      "metadata": {
        "id": "zDd7cyvxFhD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(svm_reduced_m_path, \"rb\") as f:\n",
        "    svm_reduced = pickle.load(f)"
      ],
      "metadata": {
        "id": "qF-O9y-XEFVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(lr_reduced_m_path, \"rb\") as f:\n",
        "    lr_reduced = pickle.load(f)"
      ],
      "metadata": {
        "id": "XFxjGyeJd_7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(loris1_m_path, \"rb\") as f:\n",
        "    loris1 = pickle.load(f)"
      ],
      "metadata": {
        "id": "3-VJq1-bo4z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(loris1_m_path, \"rb\") as f:\n",
        "    loris1 = pickle.load(f)"
      ],
      "metadata": {
        "id": "pSOAJ9n-owVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(loris2_m_path, \"rb\") as f:\n",
        "    loris2 = pickle.load(f)"
      ],
      "metadata": {
        "id": "MO0SmSkfow1Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}